{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266aa3e9-51b3-4765-a81c-1e0104c8fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT NECESSARY LIBRARIES\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import random\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83b16ee2-2fe4-40d2-b7bc-a6da62bc9b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded and unzipped in  /Users/rhoust/Documents/School/CSOM/Fall 2024/Advanced_ML/Project/Code\n"
     ]
    }
   ],
   "source": [
    "# DATASET DOWNLOAD\n",
    "\n",
    "def download_dataset(): \n",
    "    # Set the environment variable to point to the directory containing your .json file\n",
    "    os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()  # Make sure kaggle.json is in the current directory\n",
    "    \n",
    "    # Use the kaggle API to download the dataset\n",
    "    os.system('kaggle datasets download -d emmarex/plantdisease --unzip')\n",
    "\n",
    "download_dataset():\n",
    "\n",
    "print(\"Dataset downloaded and unzipped in \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "936f392b-7920-4448-a31d-db842d68dd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 41278/41278 [01:25<00:00, 481.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images have been resized, normalized, augmented, and saved to  /Users/rhoust/Documents/School/CSOM/Fall 2024/Advanced_ML/Project/Code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "# Paths for input and output directories\n",
    "input_dir = 'PlantVillage'\n",
    "output_dir = 'PlantVillage_Preprocessed'\n",
    "target_size = (128, 128)\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Create an ImageDataGenerator for augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Get a count of all image files for the progress bar\n",
    "image_files = []\n",
    "\n",
    "for subdir, _, files in os.walk(input_dir):\n",
    "    for file in files: \n",
    "        # Skip hidden files (e.g., .DS_Store on macOS)\n",
    "        if file.startswith('.'):\n",
    "            continue\n",
    "        # Construct full file path for each image and add to image_files list\n",
    "        full_path = os.path.join(subdir, file)\n",
    "        image_files.append(full_path)\n",
    "\n",
    "# Function to resize, normalize, and augment images with progress bar\n",
    "def preprocess_and_save_images(input_dir, output_dir, target_size):\n",
    "    for img_path in tqdm(image_files, desc=\"Processing Images\"):\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        # BASIC ERROR CHECK: DO NOT PREPROCESS IMAGES THAT ARE MISSING / CORRUPT\n",
    "        if image is not None:\n",
    "            # Resize the image\n",
    "            resized_image = cv2.resize(image, target_size)\n",
    "\n",
    "            # Normalize the image to range [0, 1]\n",
    "            normalized_image = resized_image / 255.0\n",
    "\n",
    "            # Expand dimensions to match the input shape of ImageDataGenerator (batch size of 1)\n",
    "            normalized_image = np.expand_dims(normalized_image, axis=0)\n",
    "\n",
    "            # Apply augmentation\n",
    "            i = 0\n",
    "            for batch in datagen.flow(\n",
    "                normalized_image, batch_size=1, save_to_dir=None,\n",
    "                save_prefix='aug', save_format='jpg'\n",
    "            ):\n",
    "                # Save augmented image to the output directory\n",
    "                relative_path = os.path.relpath(os.path.dirname(img_path), input_dir)\n",
    "                save_dir = os.path.join(output_dir, relative_path)\n",
    "                os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "                save_path = os.path.join(save_dir, f'aug_{i}_{os.path.basename(img_path)}')\n",
    "                cv2.imwrite(save_path, (batch[0] * 255).astype(np.uint8))\n",
    "                i += 1\n",
    "\n",
    "                # Save only one augmented version per image to limit disk space usage\n",
    "                if i >= 1:\n",
    "                    break\n",
    "\n",
    "# Run the preprocessing function\n",
    "preprocess_and_save_images(input_dir, output_dir, target_size)\n",
    "\n",
    "print(\"All images have been resized, normalized, augmented, and saved to \", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5d765af-2029-426f-bca6-9f8c25b58406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Split Directories: 100%|███████████████| 3/3 [00:00<00:00, 2356.79it/s]\n",
      "Collecting Images: 100%|███████████████████████| 16/16 [00:00<00:00, 183.20it/s]\n",
      "Copying Files: 14446it [00:06, 2136.06it/s]\n",
      "Copying Files: 3096it [00:01, 2563.29it/s]\n",
      "Copying Files: 3096it [00:01, 2744.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split and copied successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAINING / TEST SPLIT \n",
    "\n",
    "# Define directories for the split\n",
    "original_dir = \"PlantVillage_Preprocessed\"\n",
    "base_dir = \"PlantVillage_Split\"\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Create target directories for train, val, and test splits \n",
    "for split_dir in tqdm([train_dir, val_dir, test_dir], desc=\"Creating Split Directories\"):\n",
    "    if not os.path.exists(split_dir): \n",
    "        os.makedirs(split_dir)\n",
    "\n",
    "# Collect all image paths and corresponding labels \n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for label in tqdm(os.listdir(original_dir), \"Collecting Images\"):\n",
    "    label_dir = os.path.join(original_dir, label)\n",
    "    if os.path.isdir(label_dir):\n",
    "        for image_file in os.listdir(label_dir): \n",
    "            image_path = os.path.join(label_dir, image_file)\n",
    "            if os.path.isfile(image_path):\n",
    "                image_paths.append(image_path)\n",
    "                labels.append(label)\n",
    "\n",
    "# Split data into training, validation, and test sets (e.g., 70% train, 15% val, 15% test)\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.3, stratify=labels, random_state=42\n",
    ")\n",
    "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
    "    test_paths, test_labels, test_size=0.5, stratify=test_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Helper function to copy files to their respective directories\n",
    "def copy_files(image_paths, labels, split_dir):\n",
    "    for image_path, label in tqdm(zip(image_paths, labels), desc=\"Copying Files\"):\n",
    "        label_dir = os.path.join(split_dir, label)\n",
    "        if not os.path.exists(label_dir):\n",
    "            os.makedirs(label_dir)\n",
    "        shutil.copy(image_path, os.path.join(label_dir, os.path.basename(image_path)))\n",
    "\n",
    "# Copy the files to their respective split directories\n",
    "copy_files(train_paths, train_labels, train_dir)\n",
    "copy_files(val_paths, val_labels, val_dir)\n",
    "copy_files(test_paths, test_labels, test_dir)\n",
    "\n",
    "print(\"Data split and copied successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ff63789-7966-4183-b4bb-905c88afc94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,935</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m295,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │         \u001b[38;5;34m1,935\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">751,055</span> (2.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m751,055\u001b[0m (2.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">751,055</span> (2.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m751,055\u001b[0m (2.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CNN ARCHITECTURE AND IMPLEMENTATION \n",
    "\n",
    "# Number of classes in dataset\n",
    "num_classes = 15\n",
    "\n",
    "# Initialize the CNN model \n",
    "CNN = models.Sequential()\n",
    "\n",
    "CNN.add(layers.Input((128,128,3)))\n",
    "\n",
    "# Convolutional Layer 1, MaxPooling\n",
    "CNN.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
    "CNN.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# Convolutional Layer 2, MaxPooling\n",
    "CNN.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "CNN.add(layers.MaxPooling2D((2,2)))\n",
    "        \n",
    "# Convolutional Layer 3, MaxPooling\n",
    "CNN.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "CNN.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# Convolutional Layer 4, MaxPooling\n",
    "CNN.add(layers.Conv2D(256, (3,3), activation='relu'))\n",
    "CNN.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# Convolutional Layer 5, MaxPooling     \n",
    "CNN.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "CNN.add(layers.MaxPooling2D((2,2)))\n",
    "        \n",
    "# Flatten the layer \n",
    "CNN.add(layers.Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "CNN.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# Use dropout as a regularization technique\n",
    "CNN.add(layers.Dropout(0.35))\n",
    "\n",
    "# Output layer (using softmax for multi-class classification)\n",
    "CNN.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile CNN\n",
    "CNN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display model architecture\n",
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a954ab2-edca-4a07-8395-028a27c01c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14446 files belonging to 15 classes.\n",
      "Found 3096 files belonging to 15 classes.\n",
      "Epoch 1/25\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 112ms/step - accuracy: 0.2150 - loss: 3.2522 - val_accuracy: 0.4629 - val_loss: 1.6682\n",
      "Epoch 2/25\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.5006 - loss: 1.5782 - val_accuracy: 0.6483 - val_loss: 1.0349\n",
      "Epoch 3/25\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 116ms/step - accuracy: 0.6427 - loss: 1.0899 - val_accuracy: 0.7332 - val_loss: 0.8226\n",
      "Epoch 4/25\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 116ms/step - accuracy: 0.7171 - loss: 0.8631 - val_accuracy: 0.7581 - val_loss: 0.7030\n",
      "Epoch 5/25\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 119ms/step - accuracy: 0.7690 - loss: 0.7043 - val_accuracy: 0.8046 - val_loss: 0.6023\n",
      "Epoch 6/25\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 117ms/step - accuracy: 0.7939 - loss: 0.6210 - val_accuracy: 0.8030 - val_loss: 0.5992\n",
      "Epoch 7/25\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 117ms/step - accuracy: 0.8212 - loss: 0.5267 - val_accuracy: 0.8169 - val_loss: 0.5873\n",
      "Epoch 8/25\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 118ms/step - accuracy: 0.8415 - loss: 0.4689 - val_accuracy: 0.8201 - val_loss: 0.5588\n",
      "Epoch 9/25\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.8479 - loss: 0.4574 - val_accuracy: 0.8443 - val_loss: 0.4892\n",
      "Epoch 10/25\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.8629 - loss: 0.4062 - val_accuracy: 0.8282 - val_loss: 0.5840\n",
      "Epoch 11/25\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 117ms/step - accuracy: 0.8857 - loss: 0.3469 - val_accuracy: 0.7871 - val_loss: 0.7908\n",
      "Epoch 12/25\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 116ms/step - accuracy: 0.8847 - loss: 0.3359 - val_accuracy: 0.8534 - val_loss: 0.5220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['trained_CNN.pk1']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN MODEL \n",
    "\n",
    "training_path = 'PlantVillage_Split/train'\n",
    "validation_path = 'PlantVillage_Split/val'\n",
    "\n",
    "\n",
    "# Create training and validation generators \n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    training_path, \n",
    "    image_size=(128,128),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    validation_path,\n",
    "    image_size=(128,128),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Prepare computer resources efficiently - preload datasets while some are processing\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Create EarlyStopping object - stops training when loss value deteriorates on validation set\n",
    "early_stopper = EarlyStopping(monitor='val_loss',patience=3,restore_best_weights=True)\n",
    "\n",
    "# Training CNN\n",
    "training = CNN.fit(\n",
    "    train_dataset,\n",
    "    epochs=25,\n",
    "    validation_data = validation_dataset,\n",
    "    callbacks=[early_stopper]\n",
    ")\n",
    "\n",
    "# Save trained model \n",
    "joblib.dump(CNN, 'trained_CNN.pk1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d787117-f941-4938-9ef8-9c943db9e381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3096 files belonging to 15 classes.\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8334 - loss: 0.4920\n",
      "Test Loss: 0.4845602214336395, Test Accuracy: 0.8346253037452698\n"
     ]
    }
   ],
   "source": [
    "# EVALUATING MODEL ACCURACY ON TEST DATA\n",
    "test_path = 'PlantVillage_Split/test'\n",
    "CNN = joblib.load('trained_CNN.pk1')\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_path, \n",
    "    image_size=(128,128),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "test_loss, test_accuracy = CNN.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf633230-a2eb-4335-8d5a-3c165a38c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAYING TEST IMAGES (RANDOM)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Take 10 shuffled batches from the test dataset and load them into lists\n",
    "for image, label in test_dataset.take(10):\n",
    "    images.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "print(\"--- Displaying some test images...\")\n",
    "\n",
    "# Pull out a random image from all 10 batches - show the prediction and actual values for the images\n",
    "for i in range(10): \n",
    "\n",
    "    idx = random.randint(0,9)\n",
    "    sub_idx = random.randint(0,31)\n",
    "\n",
    "    # select test image\n",
    "    test_img = images[idx][sub_idx]\n",
    "\n",
    "    # get truth and prediction vals\n",
    "    truth = labels[idx][sub_idx].numpy()\n",
    "    prediction = np.argmax(CNN.predict(tf.expand_dims(test_img, axis=0), verbose=0))\n",
    "\n",
    "    # Display\n",
    "    plt.imshow(test_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Pred: {test_dataset.class_names[prediction]}, True: {test_dataset.class_names[truth]}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
